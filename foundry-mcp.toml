# foundry-mcp Configuration
#
# Provider priority with model selection for AI consultation workflows.

[workspace]
specs_dir = "./specs"

[logging]
level = "INFO"
structured = true

[server]
name = "foundry-mcp"
version = "0.2.0"

[workflow]
mode = "autonomous"
auto_validate = true
journal_enabled = true

[consultation]
# Provider priority list - first available provider wins
# Format: "[api]provider/model" or "[cli]transport[:backend/model|:model]"
priority = [
    "[cli]gemini:pro",
    "[cli]opencode:openai/gpt-5.1-codex",
    "[cli]cursor-agent:composer-1",
    "[cli]claude:opus",
]

# Per-provider overrides
[consultation.overrides]
#"[cli]opencode:openai/gpt-5.1-codex" = { timeout = 600 }

# Operational settings
default_timeout = 300
max_retries = 2
retry_delay = 5.0
fallback_enabled = true
cache_ttl = 3600

[git]
enabled = true
commit_cadence = "task"
